\subsection{Predicting PageRank}
\label{subsec:predection}

To predict the PageRank of a website, we use a model for linear regression and a neural network in RapidMiner\footnote{Appendix \ref{apn:rapidminer_setup} shows examples of the setup in the RapidMiner GUI.}. The prediction results are the results of running cross-validation, with linear sampling, and using 10\% of the data as test data. For the neural network, we use one hidden layer, and the cross validation is done in combination with parameter optimization targeting learning rate and momentum. RapidMiner makes this possible by providing an operator for specifying the parameters and their ranges, which we want for the optimization grid. For the neural network we set up 3 machines, each dedicated to one attribute subset, and ran the process on 10, 250, and 500 epochs. The latter could of course also have been automated with the parameter optimization, but in our experience this causes {RapidMiner} to freeze, and we therefore chose to do it manually. table \ref{tab:prediction_results} lists the results of running predictions on the three attribute subsets and the full set. We denote the learning rate as $l$, the epochs as $e$ and the momentum as $m$.

%\todo{Consider delete of the comment column.}
\hhtab{p{80pt}p{80pt}p{50pt}l}
{
\toprule
Model & Data & Error & Parameters\\
\midrule
Linear Regression & Rank subset & 1.254 & - \\
Linear Regression & Content subset & 1.624 & - \\
Linear Regression & Technology subset & 1.584& - \\
Linear Regression & Full set & 1.473 & - \\
Neural Net & Rank subset & 1.376 & \(e\)=500, \(l\)=0.1, \(m\)=0.34\\
Neural Net & Technology subset & 1.589 & \(e\)=250 \(l\)=0.1, \(m\)=0.25\\
Neural Net & Content subset & 1.602 & \(e\)=10, \(l\)=0.1, \(m\)=0.34\\
Neural Net & Full set & 2.141 & \(e\)=250, \(l\)=0.1 \(m\)=0.34\\
ZeroR baseline & Full set & 1.686 & -\\
\bottomrule
}{Overview of models, predicting with PageRank as the target value. The Error is the root mean squared error (RMSE) after cross validation. The target value is in its original scale (not normalised), so the error is in {PageRank} units.}{tab:prediction_results}

As table \ref{tab:prediction_results} shows, we are able to predict the page rank with an error of $1.254$, which we find to be quite good considering the limited information. Still, it is not exceptionally good, compared to the baseline error. It is a bit surprising, however, that the the neural net cannot at least produce a result similar to the linear regression. We believe the answer to this is, that the neural network over-fits the data too easily, and thus do not generalize as well. A partial conclusion on these results is, that a simple linear model may be quite adequate, for regression on this kind of data.

In the results from the neural network, we find \texttt{alexa\_links\_in} to be the most important attribute. This can be seen by looking at RapidMiner's model output, which shows that the \texttt{alexa\_links\_in} attribute has the most influence in predicting the PageRank. The visualization of this is shown in figure \ref{fig:neural_net}.

\hfig{figures/neural_nets.png}{0.9}{The importance of a connection between neurons in the neural net are indicated by the boldness of the connection. The Alexa links in is in the input layer, 7th from the top. The bias is at the bottom.}{fig:neural_net}

The correlation coefficient between the PageRank and and \texttt{alexa\_links\_in} is $0.2054$ which supports the above indications. As this is a somewhat unsatisfactory conclusion, we have decided to try running the prediction against the Rank subset minus all Alexa related attributes. The set is listed in table \ref{tab:rank_no_alexa}, which yields the results seen in table \ref{tab:rank_no_alexa_prediction}.

\hhtab{l l}
{
\toprule
Subset & Attributes in subset\\
\midrule
Rank subset without\hspace{0.4cm} & \texttt{external\_links\_count}, \texttt{page\_rank}, \texttt{title\_tag}, \\
Alexa attributes & \texttt{internal\_links\_count}, \texttt{has\_description}, \\
&\texttt{has\_keywords}, \texttt{img\_count} \\
\bottomrule
}{Rank subset without Alexa attributes.}{tab:rank_no_alexa}

\hhtab{p{80pt}p{80pt}p{50pt}l}
{
\toprule
Model & Data & Error & Parameters\\
\midrule
Linear Regression & Rank subset & 1.695 & -  \\
Neural Net & Rank subset & 1.709 & Best params from Table \ref{tab:prediction_results}\\
\bottomrule
}{Overview of models, predicting with PageRank as the target value. The Error is the average squared error after cross validation. Target value is in its original scale (not normalised).}{tab:rank_no_alexa_prediction}

As table \ref{tab:rank_no_alexa_prediction} shows, the error has gone up by removing the Alexa related attributes. Further, we see that it is possible to predict the PageRank with an average error of $1.695$. As this is not better than our baseline, it supports our conjecture that the {Alexa} related attributes, and in particular the \texttt{alexa\_links\_in} attribute, are the ones allowing an interesting prediction.