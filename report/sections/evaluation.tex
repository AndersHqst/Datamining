\section{Analysis}
\label{sec:analysis}

% \todo{I imagine this is our prime section.}
% Diagrams and numbers. Evaluate and reflect upon all results. Can we say anything?

Obviously, generating the data set is not that interesting in itself. Hence, basic statistical data was extracted, such as to provide a general overview of the most interesting information, including popular websites, choices of CMS and so forth. 

Further, clustering algorithms were used to try and identify any obvious clusters in the data. Classification/prediction algorithms were also tested, but proved less useful due to the noisy nature of the data. 

\subsection{Statistics}
\label{subsec:statistics}

Some statistics here please :)

\subsection{Clustering}
\label{subsec:clustering}

The data was clustered using three different clustering algorithms:

\begin{itemize}
\item K-Means
\item K-Medoids
\item DBSCAN
\end{itemize}

K-Means and K-Medoids were configured to look for 8 clusters\footnote{The choice of 8 clusters were based on experimentation and seemed to yield the most defined clusters.}. A mixed distance measure was used, similar to the one described in the course book \cite{book}. DBSCAN was configured to look for a minimum of 5 points using $\varepsilon = 1.0$.

Three different subsets of attributes were used for the clustering. One subset was chosen to represent the attributes that might influence the ranking of the websites. A second subset focused on the technological attributes. Finally, one subset was created to represent the content of the websites. The specific attributes can be seen in table \ref{tab:cluster_attributes}.

\htab{l l}
{
\toprule
Subset & Attributes in subset\\
\midrule
Rank subset & \texttt{alexa\_load\_time}, \texttt{alexa\_rank}, \texttt{alexa\_rank\_dk}, \\ 
& \texttt{alexa\_links\_in}, \texttt{internal\_links\_count}, \\ 
& \texttt{external\_links\_count}, \texttt{page\_rank}, \texttt{title\_tag}, \\ 
& \texttt{has\_description}, \texttt{has\_keywords}, \texttt{img\_count} \\
\midrule
Technology subset & \texttt{html5}, \texttt{html5\_tags}, \texttt{has\_js\_jquery}, \\
& \texttt{server}, \texttt{cms}, \texttt{has\_analytics} \\
\midrule
Content subset & \texttt{has\_content\_business}, \texttt{has\_content\_film}, \\ 
& \texttt{has\_content\_food}, \texttt{has\_content\_games}, \\ 
& \texttt{has\_content\_health}, \texttt{has\_content\_music}, \\
& \texttt{has\_content\_news}, \texttt{has\_content\_shop}, \\ 
& \texttt{has\_content\_sport}, \texttt{has\_content\_technology}, \\
& \texttt{has\_content\_transport}, \texttt{has\_content\_xxx} \\
\bottomrule
}{The different subsets used for in clustering process.}{tab:cluster_attributes}

\subsubsection{Clustering the rank attributes}

\subsubsection{Clustering the technology attributes}

\subsubsection{Clustering the content attributes}

Clustering the content resulted in a few prominent clusters. The most extreme of these clusters were websites without any content (according to our measure of content, that is) and the websites which satisfied almost all of our content criteria. During this clustering, we noted that the content rich websites had a better Google PageRank.

Due to this, we tried to compare the amount of content in the clusters to their assigned PageRank. This comparison was made by plotting the average PageRanks of the clusters versus the average of the content attributes\footnote{Although these attributes are actually binary, they were treated as numeric, as the average is more useful than the mode in this particular case.}. 

As it turns out, there seem to be a relationship between the average amount of content in the cluster and the assigned PageRank. This tendency can be seen in figure \ref{fig:cluster_content} for K-Medoids and in appendix \ref{app:content_pagerank} for K-Means and DBSCAN. Obviously, it must be noted that the exact relationship is still somewhat unclear, but the tendency is definitely present.

\fig{figures/kmedoids_content_pagerank.png}{0.8}{The content attributes clustered using K-Medoids. It is seen, that a large amount of content tends to result in a better PageRank. THIS FIGURE WILL BE IMPROVED IN THE FINAL REPORT.}{fig:cluster_content}

One could also plot the unclustered content attributes against the PageRank. This turned out to give a much more noisy picture, although the same tendencies were found (on average). If course, it should also be noted that the clustering does not really provide any insight which could not be found from the original dataset. However, the clustering helped us \textit{spot} the tendency.

\subsection{Prediction and classification}
\label{subsec:predictclassify}

This does not seem to work. Why? Loosely correlated features? Why does K-Means clustering make sense when K-NN does not???