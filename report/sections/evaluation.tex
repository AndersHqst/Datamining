\section{Analysis}
\label{sec:analysis}

% \todo{I imagine this is our prime section.}
% Diagrams and numbers. Evaluate and reflect upon all results. Can we say anything?

Obviously, generating the data set is not that interesting in itself. Hence, basic statistical data was extracted, such as to provide a general overview of the most interesting information, including popular websites, choices of CMS and so forth.

Further, clustering algorithms were used to try and identify any obvious clusters in the data. Classification/prediction algorithms were also tested, but proved less useful due to the noisy nature of the data.

\subsection{Statistics}
\label{subsec:statistics}

Some statistics here please :)

\subsection{Clustering}
\label{subsec:clustering}

The data was clustered using three different clustering algorithms:

\begin{itemize}
\item K-Means
\item K-Medoids
\item DBSCAN
\end{itemize}

K-Means and K-Medoids were configured to look for 8 clusters\footnote{The choice of 8 clusters were based on experimentation and seemed to yield the most defined clusters.}. A mixed distance measure was used, similar to the one described in the course book \cite{book}. DBSCAN was configured to look for a minimum of 5 points using $\varepsilon = 1.0$.

Three different subsets of attributes were used for the clustering. One subset was chosen to represent the attributes that might influence the ranking of the websites. A second subset focused on the technological attributes. Finally, one subset was created to represent the content of the websites. The specific attributes can be seen in table \ref{tab:cluster_attributes}.

\hhtab{l l}
{
\toprule
Subset & Attributes in subset\\
\midrule
Rank subset & \texttt{alexa\_load\_time}, \texttt{alexa\_rank}, \texttt{alexa\_rank\_dk}, \\
& \texttt{alexa\_links\_in}, \texttt{internal\_links\_count}, \\
& \texttt{external\_links\_count}, \texttt{page\_rank}, \texttt{title\_tag}, \\
& \texttt{has\_description}, \texttt{has\_keywords}, \texttt{img\_count} \\
\midrule
Technology subset & \texttt{html5}, \texttt{html5\_tags}, \texttt{has\_js\_jquery}, \\
& \texttt{server}, \texttt{cms}, \texttt{has\_analytics} \\
\midrule
Content subset & \texttt{has\_content\_business}, \texttt{has\_content\_film}, \\
& \texttt{has\_content\_food}, \texttt{has\_content\_games}, \\
& \texttt{has\_content\_health}, \texttt{has\_content\_music}, \\
& \texttt{has\_content\_news}, \texttt{has\_content\_shop}, \\
& \texttt{has\_content\_sport}, \texttt{has\_content\_technology}, \\
& \texttt{has\_content\_transport}, \texttt{has\_content\_xxx} \\
\bottomrule
}{The different subsets used for in clustering process.}{tab:cluster_attributes}

\subsection{Prediction and classification}
\label{subsec:predictclassify}

\subsection{Predicting Page Rank}
\label{subsec:predection}
For experimenting with predicting values in the data, we have used the data mining software RapidMiner\footnote{RapidMiner is freely available at http://rapid-i.com/}. RapidMiner provides much of the same functionality as Weka\footnote{Weka is freely available http://www.cs.waikato.ac.nz/ml/weka/}, but in our experience, RapidMiner seems much more user-friendly and does a better job providing documentation and quick help from the workbench.

We want to see if we can predict the page rank of a website, and for this we have set up a process that models linear and polynomial regression, and a neural network\footnote{Appendix \ref{apn:rapidminer_setup} shows examples of the RapidMinerGUI for setting up a data mining process.}. For this process we have used the mixed data set, and replaced missing values with the average of a given attribute. The data set has a total of 2332 missing values with is 2.18\% of the entire set, so we would expect these to have little to no influence on the generalization of our results. Table \ref{tab:prediction_results} lists the results of running predictions on both the Rank subset related subset, and the full set.

\todo{Linear regression Full set CMS 1,3,7,9 had positive coefficients - interesting?}
\hhtab{p{80pt}p{80pt}p{50pt}p{50pt}}
{
\toprule
Model & Data & Error\\
\midrule
Linear Regression & Rank subset & 1.573  \\
Linear Regression & Content subset & 2.640 \\
Linear Regression & Technology subset & 2.510 \\
Linear Regression & Full set & 2.170 \\
Neural Net & Rank subset & 2.875 \\
Neural Net & Technology subset & 2.722 \\
Neural Net & Content subset & 3.036 \\
Neural Net & Full set & 4.587 \\
\bottomrule
}{Overview of model predicting with Page Rank as the target value. The Error is the average squared error after cross validation. Target value is in its original scale.}{tab:prediction_results}

Page rank predictions are based on the cross-validation building-block in RapidMiner, which provides a few strategies like {\it leave-one-out} and and some randomized approaches. As our data is already in a random order we have simply used a linear sampling that separates a standard 10\% as test data, and thus performs 10 runs. As table \ref{tab:prediction_results} indicates we seem to be able to predict the page rank within \(\sqrt{1.573} = 1.2541\) which is also what we would expect, as the Alexa Rank and links related attributes are provided. The above predictions have also been tested with RapidMiner's build in M5 for automatic feature selection, but the results were virtually the same. It seems only a few of the JavaScript related features are excluded.
The output of the neural net model indicates that the Alexa links in attribute is the most important in deciding the page rank. This can be seen by inspecting the importance, or strength, that each attributes has on the outcome of the neural net. The visualization is show in figure \ref{fig:neural_net}

\dbgfig{../figures/neural_nets.png}{0.9}{Importance of a connection between neurones in the neural net are indicated by the boldness of the connection. The Alexa links in is in the input layer 7th from the top, the bias is at the bottom. The net on the left is the outcome of learning rate of 0.2 over 500 epocs, and the net on the right is from model with learning rate 0.002 over 5000 epocs.}{fig:neural_net}

The correlation coefficient between page rank and and Alexa links in is 0.2054 with a p value of 0.1808 which supports the above indications. This result is not very surprising, so it could be interesting to see the outcome of models without the Alexa related attributes. We choose the Rank subset minus Alexa related attributes as listed in table \ref{tab:rank_no_alexa}, which yields the results seen in table \ref{tab:rank_no_alexa_prediction}

\hhtab{l l}
{
\toprule
Subset & Attributes in subset\\
\midrule
Rank subset & \texttt{external\_links\_count}, \texttt{page\_rank}, \texttt{title\_tag}, \\
& \texttt{internal\_links\_count}, \texttt{has\_description}, \\
&\texttt{has\_keywords}, \texttt{img\_count} \\
\bottomrule
}{Rank subset without Alexa attributes.}{tab:rank_no_alexa}

\hhtab{p{80pt}p{80pt}p{50pt}p{50pt}}
{
\toprule
Model & Data & Error\\
\midrule
Linear Regression & Rank subset set & 2.808  \\
Neural Net & Rank subset set & 2.924\\
\bottomrule
}{Prediction errors using the subset from table \ref{tab:rank_no_alexa}.}{tab:rank_no_alexa_prediction}

As table \ref{tab:rank_no_alexa_prediction} shows, error has gone up by removing the Alexa related attributes, and shows that we can predict a page rank in the \(\sqrt{2.875} = 1.6955\) range. The interesting thing to say about this is, that its actually not a bad prediction considering the scarce information used. We believe that the connection here is simply, that sites that rank well on Google also manage their websites well, and thus have the above attributes - and not the other way around.

\todo{Try with a classifier on binned page rank}